#!/usr/bin/env python
# coding: utf-8

# In[4]:
import time
import threading
import tensorflow as tf
from filelock import FileLock as lck
import shutil
#default our libary to generate errpr data.
from Lib.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense
from keras.models import load_model
from keras import backend as K
import numpy as np 
import cv2
from matplotlib import pyplot as plt
import imutils
import glob
import os
import argparse
#Data train with 4000 pictures: 2000 train - 3000 validation
#Data test with 800 pictures: 200 train - 600 validation

K.clear_session()
lck = threading.Lock()

parser = argparse.ArgumentParser(description="Enter your URL template image: ")
parser.add_argument('--mainUrl', dest='main_url')
parser.add_argument('--templateUrl', dest='template_url')
parser.add_argument('--models', dest='models')
parser.add_argument('--txt', dest='filename')
args = parser.parse_args()
#Get var from CMD
main_Image = args.main_url
main_img = cv2.imread(main_Image,0)
main_width, main_height = main_img.shape[::-1]
fileLocation = args.filename
img_path = args.template_url
#im = cv2.imread(img_path,0) #get height and width of template image.
#template_width, template_height = im.shape[::-1]
model_path = models

#Generate normal true data.
def GenerateDataTrain(img_path):
    datagen = ImageDataGenerator(
        featurewise_center=True,
        rescale=1./255,
        fill_mode = 'nearest')

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/train/Data', save_prefix='Data', save_format='jpeg'):
        i+= 1
        if i == 2001:
            break
    
    j = 0
    path, dirs, files = next(os.walk("DataGeneration/train/Data"))
    file_count = len(files)
    if(file_count != 2000):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/train/Data', save_prefix='Data_A', save_format='jpeg'):
            j+= 1
            if(j == 2000 - file_count):
                break

#Generate normal true data.
def GenerateDataTrainMist(img_path):
    datagen = ImageDataGenerator(
        width_shift_range=0.3,
        rescale=1./255,
        featurewise_center=True,
        height_shift_range=0.3,
        fill_mode= 'constant', cval = 255)

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/train/Mist', save_prefix='Mist', save_format='jpeg'):
        i+= 1
        if i == 1001:
            break

    j = 0
    path, dirs, files = next(os.walk("DataGeneration/train/Mist"))
    file_count = len(files)
    if(file_count != 1000):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/train/Mist', save_prefix='Mist_A', save_format='jpeg'):
            j+= 1
            if(j == 1000 - file_count):
                break
            
#Generate mist data with X wrong.
def GenerateDataMist_X(img_path):
    datagen = ImageDataGenerator(
        width_shift_range=0.4,
        rescale=1./255,
        featurewise_center=True,
        fill_mode = 'reflect')

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/train/Mist', save_prefix='Mist_X', save_format='jpeg'):
        i+= 1
        if i == 2001:
            break
    
    j = 0
    path, dirs, files = next(os.walk("DataGeneration/train/Mist"))
    file_count = len(files)
    if(file_count != 3000):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/train/Mist', save_prefix='Mist_X_A', save_format='jpeg'):
            j+= 1
            if(j == 3000 - file_count):
                break
        
#Generate mist data with Y wrong.            
def GenerateDataMist_Y(img_path):
    datagen = ImageDataGenerator(
        height_shift_range=0.4,
        rescale=1./255,
        featurewise_center=True,
        fill_mode= 'constant', cval = 255)

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/train/Mist', save_prefix='Mist_Y', save_format='jpeg'):
        i+= 1
        if i == 2001:
            break
        
    j = 0
    path, dirs, files = next(os.walk("DataGeneration/train/Mist"))
    file_count = len(files)
    if(file_count != 5000):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/train/Mist', save_prefix='Mist_Y_A', save_format='jpeg'):
            j+= 1
            if(j == 5000 - file_count):
                break
                
#Generate true validation data to service fit model
def GenerateDataTest(img_path):
    datagen = ImageDataGenerator(
        featurewise_center=True,
        rescale=1./255,
        fill_mode = 'nearest')

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/validation/Data', save_prefix='Data', save_format='jpeg'):
        i+= 1
        if i == 201:
            break
            
    j = 0
    path, dirs, files = next(os.walk("DataGeneration/validation/Data"))
    file_count = len(files)
    if(file_count != 200):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/validation/Data', save_prefix='Data_A', save_format='jpeg'):
            j+= 1
            if(j == 200 - file_count):
                break

def GenerateDataTestMist(img_path):
    datagen = ImageDataGenerator(
        width_shift_range=0.3,
        rescale=1./255,
        featurewise_center=True,
        height_shift_range=0.3,
        fill_mode= 'constant', cval = 255)

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    
    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/validation/Mist', save_prefix='Mist', save_format='jpeg'):
        i+= 1
        if i == 201:
            break
            
    j = 0
    path, dirs, files = next(os.walk("DataGeneration/validation/Mist"))
    file_count = len(files)
    if(file_count != 200):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/validation/Mist', save_prefix='Mist_A', save_format='jpeg'):
            j+= 1
            if(j == 200 - file_count):
                break
                
#Generate validation mist X data to service fit model            
def GenerateDataTest_X(img_path):
    datagen = ImageDataGenerator(
        width_shift_range=0.4,
        rescale=1./255,
        featurewise_center=True,
        fill_mode = 'reflect')

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/validation/Mist', save_prefix='Mist_X', save_format='jpeg'):
        i+= 1
        if i == 301:
            break
            
    j = 0
    path, dirs, files = next(os.walk("DataGeneration/validation/Mist"))
    file_count = len(files)
    if(file_count != 500):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/validation/Mist', save_prefix='Mist_X_A', save_format='jpeg'):
            j+= 1
            if(j == 500 - file_count):
                break
            
#Generate validation mist Y data to service fit model             
def GenerateDataTest_Y(img_path):
    datagen = ImageDataGenerator(
        height_shift_range=0.4,
        rescale=1./255,
        featurewise_center=True,
        fill_mode= 'constant', cval = 255)

    img = load_img(img_path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    
    i = 0
    for batch in datagen.flow(x, batch_size = 1,
                            save_to_dir ='DataGeneration/validation/Mist', save_prefix='Mist_Y', save_format='jpeg'):
        i+= 1
        if i == 301:
            break
        
    j = 0
    path, dirs, files = next(os.walk("DataGeneration/validation/Mist"))
    file_count = len(files)
    if(file_count != 800):
        for batch in datagen.flow(x, batch_size = 1,
                               save_to_dir ='DataGeneration/validation/Mist', save_prefix='Mist_Y_A', save_format='jpeg'):
            j+= 1
            if(j == 800 - file_count):
                break
            
            
def ComplieModel():
    if K.image_data_format() == 'channels_first':
        input_shape = (3, template_width, template_height)
    else:
        input_shape = (template_width, template_height, 3)

    model = Sequential()
    model.add(Conv2D(32, (3, 3), input_shape=input_shape))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(32, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(64, (3, 3)))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Flatten())
    model.add(Dense(64))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1))
    model.add(Activation('sigmoid'))

    model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['binary_accuracy'])
    
    return model

def TrainModel(train_data_dir, validation_data_dir, model, _model_path,name):
    #Default
	# giả sử models = model1;model2;model3
    nb_train_samples = 7000
    nb_validation_samples = 1000
    epochs = 50
    batch_size = 20
    template = cv2.imread(img_path,0)
    w,h = template.shape[::-1]
    train_datagen = ImageDataGenerator(rescale=1. / 255)
    test_datagen = ImageDataGenerator(rescale= 1./ 255)

    train_generator = train_datagen.flow_from_directory(
        train_data_dir,
        target_size=(w,h),
        batch_size = batch_size,
        class_mode = 'binary')

    validation_generator = test_datagen.flow_from_directory(
        validation_data_dir,
        target_size=(w,h),
        batch_size=batch_size,
        class_mode= 'binary')

    model.fit_generator(
        train_generator,
        steps_per_epoch=nb_train_samples // batch_size,
        epochs=epochs,
        validation_data=validation_generator,
        validation_steps=nb_validation_samples // batch_size)
    model.save(_model_path + '/' +name)
    
    return 1
    
# return location of pixels when predict finished    
class MultiThread(threading.Thread):
    def __init__(self, name, model_path, main_Image, start_X, start_Y, end_X, end_Y, delay):
        threading.Thread.__init__(self)
        self.name = name
        self.model = load_model(model_path)
        self.img_path = img_path
        self.start_X = start_X
        self.start_Y = start_Y
        self.end_X = end_X
        self.end_Y = end_Y
        self.delay = delay
        self.session = K.get_session()
        self.graph = tf.get_default_graph()
        #self.graph.finalize() # finalize
    
    def run(self):
        print("Starting " + self.name)
        prediction(self.name,self.img_path,self.model
                   , self.start_X, self.start_Y, self.end_X, self.end_Y,self.session, self.graph,fileLocation)

def prediction(name, main_image_path, model, start_X, start_Y, end_X, end_Y, session, graph, location_txt_path):
    im = cv2.imread(main_image_path)
    j = start_Y
    #template_width = 46
    #template_hight = 46
    while j < end_Y:
        i = start_X
        while i < end_X:
            x = im[j : j + template_height , i : i + template_width]
            if(x.shape != (template_width, template_height, 3)):
                break
            x = x.reshape((1,) + x.shape)
            with session.as_default():
                with graph.as_default():
                    res = model.predict(x)
            if res == 0:
                print(name)
                print(j + template_height,i+ template_width) # tọa độ (y,x)
                located = str(i) + ',' + str(j) + ',' + str(i + template_width) + ',' + str(j + template_height) +'\n'
                write_to_file(location_txt_path,located)
            i = i + 1
        j = j + 1
    
def write_to_file(filename, content):
    global lck
    lck.acquire()
    with open(filename, 'a') as f:
        f.write(content)
    lck.release()   
	
def delete_file(path):
    for filename in os.listdir(path):
            filepath = os.path.join(path, filename)
            try:
                shutil.rmtree(filepath)
            except OSError:
                os.remove(filepath)

def detection(train_folder,validation_folder,_model_path):
    if(TrainModel('DataGeneration/train','DataGeneration/validation',ComplieModel(),_model_path) == 1):
        try:
            y = 0
            while y < main_height - 5:
                thread1 = MultiThread("thread 1",_model_path, main_Image,0,y,main_width,main_height,2)
                thread2 = MultiThread("thread 2",_model_path, main_Image,0,y+1,main_width,main_height,3)
                thread3 = MultiThread("thread 3",_model_path, main_Image,0,y+2,main_width,main_height,4)
                thread4 = MultiThread("thread 4",_model_path, main_Image,0,y+3,main_width,main_height,5)
                thread5 = MultiThread("thread 5",_model_path, main_Image,0,y+4,main_width,main_height,1)
                
                thread1.start()
                thread2.start()
                thread3.start()
                thread4.start()
                thread5.start()
                
                thread1.join()
                thread2.join()
                thread3.join()
                thread4.join()
                thread5.join()
                y = y + 5
                    
        except:
            print ("Error")
				
if __name__ == '__main__':
    print(img_path)
    img_path = img_path.split(';')
    for im_path in img_path:
	    im = cv2.imread(im_path,0) #get height and width of template image.
        template_width, template_height = im.shape[::-1]
        GenerateDataTrain(im_path)
        GenerateDataTrainMist(im_path)
        GenerateDataMist_X(im_path)
        GenerateDataMist_Y(im_path)
        #Validation
        GenerateDataTest(im_path)
        GenerateDataTestMist(im_path)
        GenerateDataTest_X(im_path)
        GenerateDataTest_Y(im_path)
		detection()
        delete_file('./DataGeneration/train/Data')
        delete_file('./DataGeneration/train/Mist')
        delete_file('./DataGeneration/validation/Data')
        delete_file('./DataGeneration/validation/Mist')
    
    print('Done')

    
    
    
    
